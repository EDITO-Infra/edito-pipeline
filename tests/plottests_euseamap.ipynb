{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Conversion\n",
    "\n",
    "In this Notebook we will do a basic data quality check of the conversion, we will also see the immense difference in speed and data accessibility between geodatabases(standard geospatial datastructures)\n",
    "\n",
    "The ability to subset specifically what we are looking for, and where we are looking for it without having to download a whole zip file and then open a larger vector dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import random\n",
    "import fiona\n",
    "from shapely.geometry import box, Point\n",
    "import xarray as xr\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import shapely.wkb\n",
    "import dask_geopandas as dgpd\n",
    "import urllib\n",
    "import s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'euseamap_2023_combined_current_and_wave_induced_energy_at_the_seabed'\n",
    "val = ['Low energy', 'Moderate energy']\n",
    "\n",
    "lat_range = [0, 80]\n",
    "lon_range = [0, 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_file ='../data/extracted_files/EUSeaMap_2023.gdb'\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "layers = fiona.listlayers(vector_file)\n",
    "layer = layers[0]\n",
    "\n",
    "gdf = gpd.read_file(vector_file, layer=layer)\n",
    "\n",
    "\n",
    "gdf_filtered = gdf[gdf[var].isin(val)]\n",
    "gdf_filtered = gdf_filtered.cx[lon_range[0]:lon_range[1], lat_range[0]:lat_range[1]]\n",
    "# Plot the geodatabase data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax.coastlines()\n",
    "gdf_filtered.plot(column=var, ax=ax, transform=ccrs.PlateCarree())\n",
    "ax.set_title('Geodatabase')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pqfile = \"../data/temp_assets/converted_arco/EUSeaMap_2023_parquet.parquet\"\n",
    "\n",
    "ddf = dd.read_parquet(pqfile)\n",
    "\n",
    "print(ddf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_geoparquet_s3(download_url):\n",
    "        \"\"\"\n",
    "        Read a GeoParquet file from a specified S3 URL. Using dask geopandas\n",
    "\n",
    "        :param download_url: The URL of the S3 asset to read.\n",
    "        :type download_url: str\n",
    "        :return: A Dask GeoDataFrame containing the GeoParquet data.\n",
    "        :rtype: dask_geopandas.GeoDataFrame\n",
    "        \"\"\"\n",
    "        parsed_url = urllib.parse.urlparse(download_url)\n",
    "        net_loc = parsed_url.netloc\n",
    "        object_key = parsed_url.path.lstrip('/')\n",
    "        s3_uri = f's3://{object_key}'\n",
    "        endpoint_url = f'https://{net_loc}'\n",
    "        fs = s3fs.S3FileSystem(anon=True, use_ssl=True, client_kwargs={'endpoint_url': endpoint_url})\n",
    "        ddf = dgpd.read_parquet(\n",
    "            s3_uri,\n",
    "            storage_options={'anon': True, 'client_kwargs' : {'endpoint_url': endpoint_url}}\n",
    "        )\n",
    "        return ddf\n",
    "\n",
    "geopqurl ='https://s3.waw3-1.cloudferro.com/emodnet/emodnet_seabed_habitats/9985/EUSeaMap_2023_geoparquet.parquet'\n",
    "pqurl2 = \"https://s3.waw3-1.cloudferro.com/emodnet/emodnet_seabed_habitats/14098/eunis_surveymaps_geoparquet_edito.parquet/\"\n",
    "\n",
    "dgdf = read_geoparquet_s3(pqurl2)\n",
    "print(dgdf) \n",
    "ddf1 = dgdf.partitions[0].compute()\n",
    "print(ddf1.head())\n",
    "\n",
    "gdf = gpd.GeoDataFrame(ddf1)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import dask_geopandas as dgpd\n",
    "import dask.dataframe as dd\n",
    "import s3fs\n",
    "def read_parquet_from_s3(url):\n",
    "    \"\"\"\n",
    "    Read a Parquet file from a specified S3 URL. The URL should be in the format 's3://bucket/key'.\n",
    "\n",
    "    :param download_url: The URL of the S3 asset to read.\n",
    "    :type download_url: str\n",
    "    :return: A Dask dataframe containing the Parquet data.\n",
    "    :rtype: dask.dataframe.DataFrame\n",
    "    \"\"\"\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    net_loc = parsed_url.netloc\n",
    "    object_key = parsed_url.path.lstrip('/')\n",
    "    s3_uri = f's3://{object_key}'\n",
    "    endpoint_url = f'https://{net_loc}'\n",
    "    fs = s3fs.S3FileSystem(anon=True, use_ssl=True, client_kwargs={'endpoint_url': endpoint_url})\n",
    "    ddf = dd.read_parquet(\n",
    "        s3_uri,\n",
    "        storage_options={'anon': True, 'client_kwargs' : {'endpoint_url': endpoint_url}},\n",
    "        engine='pyarrow'\n",
    "    )\n",
    "    return ddf\n",
    "\n",
    "download_url = 'https://s3.waw3-1.cloudferro.com/emodnet/emodnet_seabed_habitats/9985/EUSeaMap_2023_parquet.parquet'\n",
    "pqurl2 = \"https://s3.waw3-1.cloudferro.com/emodnet/emodnet_seabed_habitats/14098/eunis_surveymaps_geoparquet.parquet/\"\n",
    "\n",
    "ddf = read_parquet_from_s3(pqurl2)\n",
    "ddf1 = ddf.partitions[0].compute()\n",
    "print(ddf1.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = ddf.compute()\n",
    "\n",
    "gdf_filtered = gdf.cx[lon_range[0]:lon_range[1], lat_range[0]:lat_range[1]]\n",
    "\n",
    "print(len(gdf_filtered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot Allcomb\n",
    "\n",
    "\n",
    "# gdf_filtered = gdf_filtered[gdf_filtered['Energy'] == 3 ]\n",
    "# Plot the geodatabase data\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "ax.coastlines()\n",
    "gdf_filtered.plot(column=var, ax=ax, transform=ccrs.PlateCarree(), cmap='viridis', legend=True)\n",
    "ax.set_title('parquet')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zarr_file = '../data/temp_assets/converted_arco/EUSeaMap_2023.zarr'\n",
    "\n",
    "zarr_url = 'https://s3.waw3-1.cloudferro.com/emodnet/emodnet_seabed_habitats/9985/EUSeaMap_2023.zarr'\n",
    "\n",
    "ds = xr.open_dataset(zarr_url, engine='zarr')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dsplot = ds[var].sel(longitude=slice(lon_range[0], lon_range[1]), latitude=slice(lat_range[0], lat_range[1]))\n",
    "#encoding = ds_gdb2zarr[var].attrs['categorical_encoding']\n",
    "\n",
    "arrayval = ds[var].attrs['categorical_encoding'][val[0]]\n",
    "dsplot = dsplot.where(dsplot == arrayval)\n",
    "\n",
    "print(np.nanmax(dsplot.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the plot\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "plot = dsplot.plot(ax=ax, transform=ccrs.PlateCarree(), \n",
    "                            cmap='YlOrBr', add_colorbar=True)\n",
    "\n",
    "# Add title and labels\n",
    "ax.set_title(f'Locations {var} ', fontsize=16)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Open the Zarr dataset\n",
    "ds_gdb2zarr = xr.open_dataset(zarr_file_folk1, engine='zarr')\n",
    "\n",
    "# Specify the variable\n",
    "var = 'Energy'\n",
    "\n",
    "# Get the data array\n",
    "data = ds_gdb2zarr[var].values\n",
    "\n",
    "# Find where the array is greater than 0\n",
    "mask = data > 0\n",
    "\n",
    "# Plot the mask\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.imshow(mask, cmap='gray', interpolation='none')  # Show the mask as a binary plot\n",
    "plt.colorbar(label=\"Greater than 0 (1=True, 0=False)\")\n",
    "plt.title(f\"Locations where {var} > 0\")\n",
    "plt.xlabel(\"X-axis\")\n",
    "plt.ylabel(\"Y-axis\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
